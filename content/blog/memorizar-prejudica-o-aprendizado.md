---
title: "memorizar prejudica o aprendizado?"
date: 2021-04-24T20:00:00-03:00
slug: "memorizar prejudica o aprendizado"
description: "não"
keywords: [aprendizado]
draft: false
tags: [dessage]
math: true
toc: false
---

> _Descobri um fenômeno muito estranho: eu podia fazer uma pergunta e os alunos respondiam imediatamente. Mas quando eu fizesse a pergunta de novo – o mesmo assunto e a mesma pergunta, até onde eu conseguia –, eles simplesmente não conseguiam responder!_
>
> — [Richard Feynman](http://www.uel.br/cce/fisica/pet/EnsinoRichardFeynman.pdf)

nesse trecho feynman estava falando do recém-nascido ensino de física no brasil, mas ele poderia muito bem estar falando de algumas escolas em que estudei e tenho certeza que está soando familiar para você também. geralmente chamam isso de _decoreba_, e contrastam com o _entendimento_ — o que você realmente deveria buscar quando está aprendendo e quando está ensinando.  

essa descrição não me satisfaz porque não vejo como usá-la pra decidir o que fazer quando estou ensinando ou aprendendo. o que é entendimento? faça essa pergunta em uma sala que tem pelo menos dois filósofos e observe o que acontece. ainda assim, o feynman tem propostas muito boas, minha impressão é que elas são informadas pela experiência e pela intuição dele, e que alguém não conseguiria chegar nisso só com a descrição que ele deu.

além disso a visão _decoreba vs. entendimento_ me jogou em direções improdutivas por muito tempo, de evitar a memorização. todo aprendizado envolve algum tipo de memorização. para aprender um idioma você precisa lembrar quais são as palavras e como elas se encaixam. para aprender matemática você precisa lembrar das propriedades dos objetos, também dos nomes e das notações.

## sobreajuste

o que funcionou melhor pra mim é ver como um problema de [__sobreajuste__](https://en.wikipedia.org/wiki/Overfitting)[^1], que é um termo geralmente usado pra falar de modelos estatísticos e de inteligências artificiais. quando estamos aprendendo, estamos criando um modelo mental do que estamos estudando. se esse modelo depende de variáveis demais — por exemplo associando cada frase específica com uma resposta específica — e falha quando você apresenta situações diferentes das incluídas no treinamento, você sobreajustou.

o legal desse ponto de vista é que as pessoas da estatística e do machine learning incorporaram várias técnicas nos algoritmos deles para identificar e evitar problemas de sobreajuste. incluindo algumas que estão lá no artigo da wikipédia e eu não entendo. a mais simples é tentar vários modelos diferentes, observar quais precisam de muitas variáveis e quais não se saem bem com situações novas. tente várias vezes e você vai se aproximar para um entendimento mais profundo do assunto.

$$.$$

[^1]: em inglês overfitting
